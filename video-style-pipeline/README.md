# Video Style Analysis Pipeline / è§†é¢‘é£æ ¼åˆ†ææµæ°´çº¿

Research-grade pipeline for analyzing video style patterns: cinematography, editing, audio, and environment.

ç§‘ç ”çº§è§†é¢‘é£æ ¼åˆ†ææµæ°´çº¿ï¼šé•œå¤´è¯­è¨€ã€å‰ªè¾‘èŠ‚å¥ã€éŸ³é¢‘ç‰¹å¾ã€ç¯å¢ƒåˆ†æã€‚

## Features / åŠŸèƒ½

Analyzes 3 human-created videos to extract common stylistic patterns:

åˆ†æ3ä¸ªäººç±»åˆ›ä½œçš„è§†é¢‘ï¼Œæå–å…±åŒçš„é£æ ¼æ¨¡å¼ï¼š

- ğŸ¥ **Camera & Composition** / é•œå¤´ä¸æ„å›¾: angle, movement, framing
- ğŸ¨ **Color & Lighting** / è‰²å½©ä¸å…‰çº¿: hues, white balance, contrast, CCT
- âœ‚ï¸ **Editing & Pacing** / å‰ªè¾‘ä¸èŠ‚å¥: shot length, transitions, beat alignment
- ğŸµ **Music & Audio** / éŸ³ä¹ä¸éŸ³é¢‘: tempo, energy, style, speech ratio
- ğŸ  **Environment** / ç¯å¢ƒ: scene type, countertop, utensils (optional YOLO)
- ğŸ—£ï¸ **Narration** / æ—ç™½: speech rate, catchphrases (optional Whisper)

## Installation

### Basic Installation

```bash
pip install -r requirements.txt
```

### Optional Enhancements

**YOLOv8** (kitchen/utensils detection):
```bash
pip install ultralytics
```

**Whisper ASR** (narration analysis):
```bash
# Option 1: faster-whisper (recommended for speed)
pip install faster-whisper

# Option 2: OpenAI Whisper
pip install openai-whisper
```

**Advanced Scene Detection** (optional upgrades):
```bash
pip install scenedetect[opencv]
pip install essentia-tensorflow  # For advanced music analysis
```

## Usage

### Basic Usage

Place 3 human-created videos in the `videos/` directory, then:

```bash
./analyze.sh
```

Or use the Python script directly:

```bash
python src/analyze.py \
  --videos videos/v1.mp4 videos/v2.mp4 videos/v3.mp4 \
  --report output_report.docx
```

### With Audio Pre-extraction

For better audio analysis, extract audio first:

```bash
# Extract audio (22.05kHz mono wav)
ffmpeg -i videos/v1.mp4 -ar 22050 -ac 1 work/v1.wav
ffmpeg -i videos/v2.mp4 -ar 22050 -ac 1 work/v2.wav
ffmpeg -i videos/v3.mp4 -ar 22050 -ac 1 work/v3.wav

python src/analyze.py \
  --videos videos/v1.mp4 videos/v2.mp4 videos/v3.mp4 \
  --audios work/v1.wav work/v2.wav work/v3.wav \
  --report output_report.docx
```

### Enable Optional Features

```bash
python src/analyze.py \
  --videos videos/v1.mp4 videos/v2.mp4 videos/v3.mp4 \
  --enable-yolo \
  --enable-asr \
  --frames edge \
  --report output_report.docx
```

### Options

- `--videos`: 3 video paths (required)
- `--audios`: 3 pre-extracted wav files (optional, recommended)
- `--report`: Output Word document path (required)
- `--frames`: Contact sheet style: `mosaic`, `edge`, or `off` (default: `edge`)
- `--enable-yolo`: Enable YOLOv8 kitchen/utensils detection
- `--enable-asr`: Enable Whisper ASR for narration analysis

## Project Structure

```
video-style-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile                    # Build/test/clean commands
â”œâ”€â”€ analyze.sh                  # Quick-start bash script
â”œâ”€â”€ videos/                     # Place your 3 videos here
â”‚   â”œâ”€â”€ v1.mp4
â”‚   â”œâ”€â”€ v2.mp4
â”‚   â””â”€â”€ v3.mp4
â”œâ”€â”€ work/                       # Runtime: audio extracts, frames, cache
â””â”€â”€ src/
    â”œâ”€â”€ analyze.py              # Main orchestration script
    â”œâ”€â”€ metrics_visual.py       # Visual/editing/color/white balance
    â”œâ”€â”€ metrics_audio.py        # BPM/beat/energy/narration ratio
    â”œâ”€â”€ metrics_asr.py          # (Optional) Whisper transcription
    â”œâ”€â”€ metrics_yolo.py         # (Optional) YOLOv8 detection
    â””â”€â”€ report_word.py          # Word report generation
```

## Output

The pipeline generates a `.docx` report containing:
1. **Cross-video common elements**: majority consensus across 3 videos
2. **Per-video metrics**: detailed breakdown for each video
3. **Optional screenshots**: contact sheets showing key frames
4. **Upgrade suggestions**: recommendations for enhanced analysis

## Compliance & Ethics

- Analyze only **human-created content** (e.g., verified via Deepware)
- No portrait/face analysis
- No external copyrighted assets
- Suitable for research and style transfer applications

## Optional Enhancements / å¯é€‰å¢å¼º

Want better accuracy? See **OPTIMIZATION.md** for detailed recommendations:

æƒ³è¦æ›´é«˜å‡†ç¡®ç‡ï¼ŸæŸ¥çœ‹ **OPTIMIZATION.md** è·å–è¯¦ç»†å‡çº§å»ºè®®ï¼š

**High Priority Tools / é«˜ä¼˜å…ˆçº§å·¥å…·:**
- ğŸ”´ **PySceneDetect**: 95% shot detection accuracy (vs. 70% current)
- ğŸ”´ **Essentia**: 100+ music features (vs. 5 current)  
- ğŸ”´ **Pyannote**: Speaker diarization (who speaks when)
- ğŸ”´ **Places365**: Scene classification (365 scene types)

**Medium Priority / ä¸­ä¼˜å…ˆçº§:**
- ğŸŸ¡ **Demucs**: Audio source separation
- ğŸŸ¡ **OpenSMILE**: 6000+ prosody features
- ğŸŸ¡ **Madmom**: Better beat tracking

Expected improvement: 50-95% analysis depth / é¢„æœŸæå‡ï¼š50-95%åˆ†ææ·±åº¦

## Documentation / æ–‡æ¡£

- **README.md** (this file) - Main documentation / ä¸»æ–‡æ¡£
- **QUICKSTART.md** - 5-minute tutorial / 5åˆ†é’Ÿæ•™ç¨‹
- **OPTIMIZATION.md** - Upgrade guide / å‡çº§æŒ‡å—

## References / å‚è€ƒ

**Core Dependencies:** OpenCV, NumPy, librosa, python-docx, Pillow  
**Optional:** YOLOv8, Whisper, loguru, tqdm  
**Optimization:** See OPTIMIZATION.md for advanced tools

## License

MIT License - Research and educational use

## Citation

If you use this pipeline in your research, please cite appropriately and ensure compliance with all component licenses.

