# Video Style Analysis Pipeline / è§†é¢‘é£æ ¼åˆ†ææµæ°´çº¿

Research-grade pipeline for analyzing video style patterns: cinematography, editing, audio, and environment.

ç§‘ç ”çº§è§†é¢‘é£æ ¼åˆ†ææµæ°´çº¿ï¼šé•œå¤´è¯­è¨€ã€å‰ªè¾‘èŠ‚å¥ã€éŸ³é¢‘ç‰¹å¾ã€ç¯å¢ƒåˆ†æã€‚

## Features / åŠŸèƒ½

Analyzes 3 human-created videos to extract common stylistic patterns:

åˆ†æ3ä¸ªäººç±»åˆ›ä½œçš„è§†é¢‘ï¼Œæå–å…±åŒçš„é£æ ¼æ¨¡å¼ï¼š

- ğŸ¥ **Camera & Composition** / é•œå¤´ä¸æ„å›¾: angle, movement, framing
- ğŸ¨ **Color & Lighting** / è‰²å½©ä¸å…‰çº¿: hues, white balance, contrast, CCT
- âœ‚ï¸ **Editing & Pacing** / å‰ªè¾‘ä¸èŠ‚å¥: shot length, transitions, beat alignment
- ğŸµ **Music & Audio** / éŸ³ä¹ä¸éŸ³é¢‘: tempo, energy, style, speech ratio
- ğŸ  **Environment** / ç¯å¢ƒ: scene type, countertop, utensils (optional YOLO)
- ğŸ—£ï¸ **Narration** / æ—ç™½: speech rate, catchphrases (optional Whisper)

## Installation

### Basic Installation

```bash
pip install -r requirements.txt
```

### Optional Enhancements

**YOLOv8** (kitchen/utensils detection):
```bash
pip install ultralytics
```

**Whisper ASR** (narration analysis):
```bash
# Option 1: faster-whisper (recommended for speed)
pip install faster-whisper

# Option 2: OpenAI Whisper
pip install openai-whisper
```

**Advanced Scene Detection** (optional upgrades):
```bash
pip install scenedetect[opencv]
pip install essentia-tensorflow  # For advanced music analysis
```

## Usage

### Basic Usage

Place 3 human-created videos in the `videos/` directory, then:

```bash
# Method 1: Shell script / Shellè„šæœ¬
./analyze.sh

# Method 2: Python main / Pythonä¸»å…¥å£
python main.py -v videos/v1.mp4 videos/v2.mp4 videos/v3.mp4 -o report.docx

# Method 3: Makefile
make run
```

### With Audio Pre-extraction / å¸¦éŸ³é¢‘æå–

For better audio analysis, extract audio first:

```bash
# Extract audio / æå–éŸ³é¢‘ (22.05kHz mono wav)
make extract-audio

# Then run / ç„¶åè¿è¡Œ
python main.py -v videos/v1.mp4 videos/v2.mp4 videos/v3.mp4 \
               -a work/v1.wav work/v2.wav work/v3.wav \
               -o report.docx
```

### Enable Optional Features / å¯ç”¨å¯é€‰åŠŸèƒ½

```bash
# Enable all features / å¯ç”¨æ‰€æœ‰åŠŸèƒ½
python main.py -v videos/v1.mp4 videos/v2.mp4 videos/v3.mp4 \
               --yolo --asr \
               -o report.docx

# Or use Makefile / æˆ–ä½¿ç”¨Makefile
make run-full
```

### Command-Line Options / å‘½ä»¤è¡Œé€‰é¡¹

```bash
python main.py --help
```

**Required / å¿…éœ€:**
- `-v, --videos`: 3 video paths / 3ä¸ªè§†é¢‘è·¯å¾„
- `-o, --output`: Output .docx path / è¾“å‡ºæŠ¥å‘Šè·¯å¾„

**Optional / å¯é€‰:**
- `-a, --audios`: 3 audio wav files / 3ä¸ªéŸ³é¢‘æ–‡ä»¶
- `--yolo`: Enable YOLOv8 detection / å¯ç”¨ç‰©ä½“æ£€æµ‹
- `--asr`: Enable Whisper ASR / å¯ç”¨è¯­éŸ³è¯†åˆ«
- `--frames`: Screenshot style (edge/mosaic/off) / æˆªå›¾æ¨¡å¼
- `--work-dir`: Working directory / å·¥ä½œç›®å½• (default: work)

## Project Structure

```
video-style-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile                    # Build/test/clean commands
â”œâ”€â”€ analyze.sh                  # Quick-start bash script
â”œâ”€â”€ videos/                     # Place your 3 videos here
â”‚   â”œâ”€â”€ v1.mp4
â”‚   â”œâ”€â”€ v2.mp4
â”‚   â””â”€â”€ v3.mp4
â”œâ”€â”€ work/                       # Runtime: audio extracts, frames, cache
â””â”€â”€ src/
    â”œâ”€â”€ analyze.py              # Main orchestration script
    â”œâ”€â”€ metrics_visual.py       # Visual/editing/color/white balance
    â”œâ”€â”€ metrics_audio.py        # BPM/beat/energy/narration ratio
    â”œâ”€â”€ metrics_asr.py          # (Optional) Whisper transcription
    â”œâ”€â”€ metrics_yolo.py         # (Optional) YOLOv8 detection
    â””â”€â”€ report_word.py          # Word report generation
```

## Output

The pipeline generates a `.docx` report containing:
1. **Cross-video common elements**: majority consensus across 3 videos
2. **Per-video metrics**: detailed breakdown for each video
3. **Optional screenshots**: contact sheets showing key frames
4. **Upgrade suggestions**: recommendations for enhanced analysis

## Compliance & Ethics

- Analyze only **human-created content** (e.g., verified via Deepware)
- No portrait/face analysis
- No external copyrighted assets
- Suitable for research and style transfer applications

## Optional Enhancements / å¯é€‰å¢å¼º

Want better accuracy? See **OPTIMIZATION.md** for detailed recommendations:

æƒ³è¦æ›´é«˜å‡†ç¡®ç‡ï¼ŸæŸ¥çœ‹ **OPTIMIZATION.md** è·å–è¯¦ç»†å‡çº§å»ºè®®ï¼š

**High Priority Tools / é«˜ä¼˜å…ˆçº§å·¥å…·:**
- ğŸ”´ **PySceneDetect**: 95% shot detection accuracy (vs. 70% current)
- ğŸ”´ **Essentia**: 100+ music features (vs. 5 current)  
- ğŸ”´ **Pyannote**: Speaker diarization (who speaks when)
- ğŸ”´ **Places365**: Scene classification (365 scene types)

**Medium Priority / ä¸­ä¼˜å…ˆçº§:**
- ğŸŸ¡ **Demucs**: Audio source separation
- ğŸŸ¡ **OpenSMILE**: 6000+ prosody features
- ğŸŸ¡ **Madmom**: Better beat tracking

Expected improvement: 50-95% analysis depth / é¢„æœŸæå‡ï¼š50-95%åˆ†ææ·±åº¦

## Documentation / æ–‡æ¡£

- **README.md** (this file) - Main documentation / ä¸»æ–‡æ¡£
- **QUICKSTART.md** - 5-minute tutorial / 5åˆ†é’Ÿæ•™ç¨‹
- **OPTIMIZATION.md** - Upgrade guide / å‡çº§æŒ‡å—

## References / å‚è€ƒ

**Core Dependencies:** OpenCV, NumPy, librosa, python-docx, Pillow  
**Optional:** YOLOv8, Whisper, loguru, tqdm  
**Optimization:** See OPTIMIZATION.md for advanced tools

## License

MIT License - Research and educational use

## Citation

If you use this pipeline in your research, please cite appropriately and ensure compliance with all component licenses.

